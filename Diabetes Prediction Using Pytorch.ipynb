{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "a328c092246040e49735948243fa2c60",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": [
    "# Import Libraries"
   ],
   "block_group": "0d09150ff30044eba8c6e46783cd9ffc"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "520b549e",
    "execution_start": 1699160500587,
    "execution_millis": 3782,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "306bf0e02b9f4a4db3d9deba9e3db6bc",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "end_time": "2023-11-05T05:17:51.586928300Z",
     "start_time": "2023-11-05T05:17:50.989340600Z"
    }
   },
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ],
   "block_group": "150025d511ba43a8aa2cb8f05776af16",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "You need either charset_normalizer or chardet installed",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mException\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9928\\3648081119.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;31m# PyTorch libraries\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0moptim\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdatasets\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mio\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mutils\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mextension\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_HAS_OPS\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_optical_flow\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mFlyingChairs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFlyingThings3D\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mHD1K\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mKittiFlow\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSintel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m from ._stereo_matching import (\n\u001B[0;32m      3\u001B[0m     \u001B[0mCarlaStereo\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mCREStereo\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mETH3DStereo\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\_optical_flow.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_read_png_16\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m_read_pfm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverify_str_arg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mvision\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mVisionDataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mrequests\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_zoo\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    104\u001B[0m \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    105\u001B[0m     check_compatibility(\n\u001B[1;32m--> 106\u001B[1;33m         \u001B[0murllib3\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__version__\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchardet_version\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcharset_normalizer_version\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    107\u001B[0m     )\n\u001B[0;32m    108\u001B[0m \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mAssertionError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\requests\\__init__.py\u001B[0m in \u001B[0;36mcheck_compatibility\u001B[1;34m(urllib3_version, chardet_version, charset_normalizer_version)\u001B[0m\n\u001B[0;32m     84\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mmajor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mminor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatch\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 86\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"You need either charset_normalizer or chardet installed\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     87\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mException\u001B[0m: You need either charset_normalizer or chardet installed"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "1a52203064454ce6b98c983611fba7cd",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": [
    "# Load the dataset"
   ],
   "block_group": "c0df36ee0b1b47bdb0bbfbe155dc4ace"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "3d678ffd",
    "execution_start": 1699160504372,
    "execution_millis": 278,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "999d843eacb04cb4ba5fcc9c69de1dc2",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.052323200Z"
    }
   },
   "source": [
    "diabetes_data = load_diabetes()\n",
    "df = pd.DataFrame(data=diabetes_data.data, columns=diabetes_data.feature_names)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "df['progression'] = diabetes_data.target\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('diabetes_data.csv', index=False)\n",
    "\n",
    "\n",
    "df"
   ],
   "block_group": "30c272b075b5499e971011482070f650",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "underline": true
      },
      "toCodePoint": 6,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "a790b3dd50c24e6c8ead659d11e3c134",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": [
    "# Step 1 : Prep the data"
   ],
   "block_group": "6453eb84165a44c4811a0a45a7284cd7"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "2d0daf724d32412bb682ad528be0ab75",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [],
   "block_group": "90b5336f95264c929fe5e9131a21d7ab"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "edca1c2169db4b83bb2fa269c1d53528",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Load for Missing , Null, NAN Values"
   ],
   "block_group": "b24fefb405384bf1b8393ecf9e170c79"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "60a1a76a1f0642d68c1ef8e72ce115ca",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Find Outliers"
   ],
   "block_group": "0c4649b22e934ce5abec8a41401e2710"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "1215101e650f41168d1c049ad758aeb0",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Transform the data such that all entries should be numeric"
   ],
   "block_group": "6e665f4b7dfc410d91c59127906235c5"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "b8c64e595a3243fba8615814273ad044",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [],
   "block_group": "53769a242d424bedacdf9f67abf04865"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "20869176",
    "execution_start": 1699160504695,
    "execution_millis": 10,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "84a692ed65ae424d8b896042ab2c1a46",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.052323200Z"
    }
   },
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for NaN values\n",
    "print(df.isna().sum())\n"
   ],
   "block_group": "0db43d06e1a84cd2a6ce2f6f0cbd0aab",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "fb677e4612f340298d3f7a903d7af3c0",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "We would have them we would handle them in the following manner:"
   ],
   "block_group": "cafd412aa217493aa9a3e0006d68db7b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 50,
      "fromCodePoint": 26
     }
    ],
    "cell_id": "ffd6288cd1a04cc394151e8244f3e1d5",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Check for missing values\n",
    "print(df.isnull().sum())"
   ],
   "block_group": "4a7e7ef45c224f739d40f424f8f983fd"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 44,
      "fromCodePoint": 22
     }
    ],
    "cell_id": "f5537be6da244a4eaa4fabe891339136",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Check for NaN values\n",
    "print(df.isna().sum())"
   ],
   "block_group": "764766150c5b4d7a826356306028e267"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 68,
      "fromCodePoint": 34
     }
    ],
    "cell_id": "a7a9db04f327467487bb5016bbf0e302",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Filling missing values with mean\n",
    "df.fillna(df.mean(), inplace=True)"
   ],
   "block_group": "58bc40c5a2bb441aae627b2e5270d635"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 72,
      "fromCodePoint": 49
     }
    ],
    "cell_id": "aa3c8e8649414c439b2a1d0ed2d57921",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Alternatively, to drop rows with any NaN values\n",
    "df.dropna(inplace=True)\n"
   ],
   "block_group": "d4fc12f0f1ae47f9940418d85b96d2e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "44ca97dfae434215ba78cdf520a98d5c",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- FInd Outliers"
   ],
   "block_group": "4b07a35d3a5a43afaca76ae2fb8dec6f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "83f8b37c",
    "execution_start": 1699160504695,
    "execution_millis": 9,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "a566ef4ccf5e486983c46f041edc3ddc",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.068109300Z"
    }
   },
   "source": [
    "# Look for outliers using the Interquartile Range (IQR) method\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define an outlier as being beyond 1.5 times the IQR from the Q1 or Q3\n",
    "# This is a common rule of thumb for identifying outliers\n",
    "outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "print(f\"\\nNumber of rows with outliers: {outliers.sum()}\")"
   ],
   "block_group": "7add05cf31314e379125fe8577e4249c",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9928\\933849688.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Look for outliers using the Interquartile Range (IQR) method\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mQ1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mquantile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.25\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mQ3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mquantile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.75\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mIQR\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mQ3\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mQ1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "dafd848001ba4972b3f578ad16efa0ac",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Convert all data to Numeric"
   ],
   "block_group": "b5ed5543d0c54cc0b3d0c2da6f7137d6"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "2be1cf00",
    "execution_start": 1699160504738,
    "execution_millis": 23,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "21c0eca0f5724d8c93a631ba6dd5580f",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.099443700Z"
    }
   },
   "source": [
    "\n",
    "for column in df.columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "\n"
   ],
   "block_group": "98e4d1e488c24393b3608caa4f08def5",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "underline": true
      },
      "toCodePoint": 6,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "f2e70a1ee6984adc964d3baea5299e42",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": [
    "# Step 2: List all the data types as numeric, categorical etc."
   ],
   "block_group": "dfa7c158886f4ef897507713cbbfef1d"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "df083296ad914b1ba48f2c1761ff8623",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- List all types of data"
   ],
   "block_group": "108c2822a2b64088adecba0a49f6b311"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "85db6318",
    "execution_start": 1699160504748,
    "execution_millis": 24,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "a0199484c9b94df09f930aef0ed90d1c",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.099443700Z"
    }
   },
   "source": [
    "# List all the columns and their data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Programmatically separate numeric and categorical columns based on dtype\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_columns = df.select_dtypes(exclude=['number', 'bool']).columns.tolist()\n",
    "\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if df[col].nunique() < 10:  # nunique() returns the number of unique values\n",
    "        numeric_columns.remove(col)\n",
    "        categorical_columns.append(col)\n",
    "\n",
    "print(\"Numeric columns:\", numeric_columns)\n",
    "print(\"Categorical columns:\", categorical_columns)\n"
   ],
   "block_group": "8a47ca344ec24900b40fd99f7c849b2d",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "underline": true
      },
      "toCodePoint": 5,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "d3e5e4119c0f4e9993601b33be0f066d",
    "deepnote_cell_type": "text-cell-h1"
   },
   "source": [
    "# Step3: Perform EDA"
   ],
   "block_group": "f358c02c85054f44bb598b186e709677"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "5ca7074c50ac4063aea1fbc74b9248f8",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### We first Perform the plotting using standard pandas and matplotlib"
   ],
   "block_group": "70ac9e3c73ff41ddaf1e0ca3cf633fd1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "2b3fb204ab274e89be6a51f7a32f6fdd",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "We will use the following plots "
   ],
   "block_group": "084669d00aa842588d65c1040f196e0c"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 11,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "1606403ddbe84712815bbf3e12a893fb",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Pairplots: To visualize the distributions and relationships"
   ],
   "block_group": "166cacf2d6914184879b35a9900fbd0a"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 26,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "4293f317b95a40bda46396698f888d9d",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Correlation Matrix Heatmap:A graphical representation of the correlation coefficients between every pair of variables in the data, providing a quick visual summary of how each variable is related to the others."
   ],
   "block_group": "abeb449a229b4e809d5a63c649dbe39f"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 10,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "598064a330e741f9888de3cf5ec112e0",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Histograms: To visualize the distributions of each feature"
   ],
   "block_group": "c64fc02d98af4ff9a7d9aaa9d53f9728"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 9,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "d4713b236b4a4ec0bdd5218d1cf3fbb3",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Box plots: To check for outliers in each feature"
   ],
   "block_group": "1f4bce34b26245509fab369331bac9c4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 13,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "21250978a0cd470781004ba688637bd3",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Scatter plots: Plot these with the target variable to visualize individual relationships"
   ],
   "block_group": "3ca936ae242143ab81d2ae6186f9c144"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "de314c85",
    "execution_start": 1699160504762,
    "execution_millis": 51492,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "2526f998d7c644ceb77bcf2a889e28ba",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.146848Z"
    }
   },
   "source": [
    "# Pairplot to visualize the distributions and relationships\n",
    "print(\"\\nPairplot showing the distributions and relationships between features:\")\n",
    "sns.pairplot(df)\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix heatmap\n",
    "print(\"\\nCorrelation matrix heatmap showing the correlation coefficients between features:\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\")\n",
    "plt.tight_layout()  # Adjust the layout to fit all labels and titles\n",
    "plt.show()\n",
    "\n",
    "# Histograms to visualize the distributions of each feature\n",
    "print(\"\\nHistograms showing the distributions of each feature:\")\n",
    "df.hist(bins=15, figsize=(15, 10), layout=(3, 4))\n",
    "plt.tight_layout()  # Adjust the layout to fit all labels and titles\n",
    "plt.show()\n",
    "\n",
    "# Box plots to check for outliers in each feature\n",
    "print(\"\\nBox plots showing the distribution and potential outliers for each feature:\")\n",
    "df.plot(kind='box', subplots=True, layout=(3, 4), figsize=(15, 10))\n",
    "plt.tight_layout()  # Adjust the layout to fit all labels and titles\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots with the target variable to visualize individual relationships\n",
    "print(\"\\nScatter plots showing the relationships between each feature and the target variable 'progression':\")\n",
    "for col in df.columns[:-1]:  # Exclude the target variable itself\n",
    "    df.plot(kind='scatter', x=col, y='progression', figsize=(8, 5))\n",
    "    plt.title(f'Scatter plot of {col} vs Progression')\n",
    "    plt.tight_layout()  # Adjust the layout to fit the label and title\n",
    "    plt.show()"
   ],
   "block_group": "501f0678ed8d40a38dc4c7f334238b76",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairplot showing the distributions and relationships between features:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9928\\2040894986.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Pairplot to visualize the distributions and relationships\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"\\nPairplot showing the distributions and relationships between features:\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0msns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpairplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "5ce59aa3",
    "execution_start": 1699160262697,
    "execution_millis": 4674,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "fd17c191a36b4f47acad0488432180a0",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.162436100Z"
    }
   },
   "source": [
    "!pip install torch_inspect==0.0.3"
   ],
   "block_group": "6a1b7bd0cab64f6ead0ad932b4066c0a",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "6bc736da723942df887f61d48bdccfa2",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### Plotting Using Pytorch and Matplotlib"
   ],
   "block_group": "e174fd25eeba4b9997934dcf1b19a7ea"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "4c332c1c",
    "execution_start": 1699160267381,
    "execution_millis": 2300,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "1e3a36aedd8d4e29aa4b882960db62b7",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.162436100Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the model architecture is the same as the one you saved earlier\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load the diabetes dataset\n",
    "data = pd.read_csv('diabetes_data.csv')\n",
    "\n",
    "# Convert the data to PyTorch Tensors and normalize if necessary\n",
    "x = torch.tensor(data.drop('progression', axis=1).values, dtype=torch.float32)\n",
    "y = torch.tensor(data['progression'].values, dtype=torch.float32)\n",
    "\n",
    "# Initialize the model\n",
    "input_size = x.size(1)\n",
    "model = Net(input_size)\n",
    "\n",
    "# Load the saved state dictionary into the model\n",
    "state_dict = torch.load('diabetes_model.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Now let's plot the histogram of activations for each layer\n",
    "# We will collect activations in a forward hook\n",
    "activations = []\n",
    "\n",
    "def get_activation(layer, input, output):\n",
    "    activations.append(output.detach())\n",
    "\n",
    "# Register hook for each layer\n",
    "hooks = []\n",
    "for layer in model.children():\n",
    "    hooks.append(layer.register_forward_hook(get_activation))\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    model(x)\n",
    "\n",
    "# Remove hooks (good practice to avoid memory leaks)\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "# Plotting the activations\n",
    "for i, activation in enumerate(activations):\n",
    "    plt.hist(activation.numpy().flatten(), bins=50)\n",
    "    plt.title(f'Layer {i+1} activations')\n",
    "    plt.xlabel('Activation')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ],
   "block_group": "8ae4e5ef42a740c8b7dd92386e50b27a",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "feb960661006454593df97b5deb7c7ea",
    "deepnote_cell_type": "text-cell-h2"
   },
   "source": [
    "## Train models using pytorch"
   ],
   "block_group": "aeeeb9d820c04840a2c22596d58e0fc5"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "6d99ce3271ea496f9928c3d670ad770e",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "Before training the models we do the following things"
   ],
   "block_group": "0e5d6030c7db4f2da585644670360df7"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "630e761ed4bf441e8b938d5347625883",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Remove Nan and Null values since our dataset has no such values we can skip it"
   ],
   "block_group": "5fb9c5a612aa41559bea824be8a0e285"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "5fe2e8f6fa8e44c8a6c067bc98740919",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Remove outliers by using Z-Score"
   ],
   "block_group": "66abfcefdacd478683c0927d11e33773"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "13f5d616fa2144e4a357efccfc4fa24a",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Consider only highly correlated features with the target variable"
   ],
   "block_group": "2242503a88dc427b996a590c455bf89c"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "c2b3074057104382b9eb27c2199c487f",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Perform Feature Scaling and Feature Engineering"
   ],
   "block_group": "dfebd812bedc45dbb89d46811cce78ae"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "af86775b2836458dbb3cd282ce35511f",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### Remove Outliers Using Z-Scores"
   ],
   "block_group": "0e30e0a0fffa4b58be97ca07485294e3"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "01a66a5116b84e4889d1f09d13b4b332",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [],
   "block_group": "b7519928793f45858f7fbcb9b4bac414"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "7c9c2b5d",
    "execution_start": 1699160269735,
    "execution_millis": 1128,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "b652ca6f012c41cda09ffc81b93907d1",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.181242800Z"
    }
   },
   "source": [
    "# Visualize boxplots before outlier removal\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.boxplot(data=df)\n",
    "plt.title('Boxplots Before Outlier Removal')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = stats.zscore(df)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "\n",
    "# Filter out the outliers\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "df_no_outliers = df[filtered_entries]\n",
    "\n",
    "# Calculate and print the number of outliers removed\n",
    "outliers_removed = len(df) - len(df_no_outliers)\n",
    "print(f'Number of outliers removed: {outliers_removed}')\n",
    "\n",
    "# Visualize boxplots after outlier removal\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.boxplot(data=df_no_outliers)\n",
    "plt.title('Boxplots After Outlier Removal')\n",
    "plt.show()\n"
   ],
   "block_group": "a78822f0ad854eeeb54399405c8536fa",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9928\\388874769.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Visualize boxplots before outlier removal\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m16\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0msns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mboxplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Boxplots Before Outlier Removal'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "24d58a53",
    "execution_start": 1699160270872,
    "execution_millis": 1801,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "3a84fecf22e34038a35beb1981f9e672",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.241994600Z"
    }
   },
   "source": [
    "# # Calculate the correlation matrix\n",
    "# corr_matrix = df.corr()\n",
    "\n",
    "# # Set the threshold for high correlation\n",
    "# threshold = 0.35\n",
    "\n",
    "# # Identify highly correlated features\n",
    "# # We'll create a mask to identify correlation coefficients above the threshold\n",
    "# highly_corr_features = np.where(np.abs(corr_matrix) > threshold)\n",
    "\n",
    "# # Create a set of pairs to understand which features have high correlation\n",
    "# # Exclude self correlation of features (i.e., correlation of a feature with itself)\n",
    "# feature_pairs = set()\n",
    "# for i, j in zip(*highly_corr_features):\n",
    "#     if i != j and (j, i) not in feature_pairs:\n",
    "#         feature_pairs.add((i, j))\n",
    "\n",
    "# # Print out highly correlated features and the correlation values\n",
    "# print(\"Highly correlated feature pairs:\")\n",
    "# for i, j in feature_pairs:\n",
    "#     print(f\"{df.columns[i]} and {df.columns[j]} with correlation {(corr_matrix.iloc[i, j]):.2f}\")\n",
    "\n",
    "# # Visualize the correlation matrix\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "# plt.title(\"Correlation Matrix\")\n",
    "# plt.show()\n",
    "\n",
    "# # Identify features to remove (those not in the highly correlated pairs)\n",
    "# features_to_remove = [df.columns[i] for i in range(corr_matrix.shape[0]) if all(\n",
    "#     (i, j) not in feature_pairs and (j, i) not in feature_pairs for j in range(corr_matrix.shape[0]))]\n",
    "\n",
    "# # Remove less correlated features from the DataFrame\n",
    "# df_reduced = df.drop(columns=features_to_remove)\n",
    "\n",
    "# # Display which features were removed\n",
    "# print(f\"Features removed for having correlation less than {threshold}: {features_to_remove}\")\n",
    "\n",
    "\n",
    "# print(f\"The modified dataset is\")\n",
    "\n",
    "# df_reduced\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'progression' is the target column\n",
    "target_column = 'progression'  # Replace with your actual target column name if different\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Visualize the heatmap of the correlation matrix before removing low-correlation features\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Heatmap of the Correlation Matrix Before Removing Low-Correlation Features')\n",
    "plt.show()\n",
    "\n",
    "# Consider a feature highly correlated when the absolute correlation coefficient is above a threshold, e.g., 0.5\n",
    "threshold = 0.40\n",
    "features_to_consider = correlation_matrix.index[abs(correlation_matrix[target_column]) > threshold].tolist()\n",
    "features_to_remove = correlation_matrix.index[abs(correlation_matrix[target_column]) <= threshold].tolist()\n",
    "\n",
    "# Remove the target variable from the features to consider if it's included\n",
    "if target_column in features_to_consider:\n",
    "    features_to_consider.remove(target_column)\n",
    "\n",
    "print(f'Highly correlated features with progression to be considered: {features_to_consider}')\n",
    "print(f'Features removed due to low correlation with progression: {features_to_remove}')\n",
    "\n",
    "# Show heatmap with low-correlation features to be removed\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix.drop(features_to_consider, axis=0).drop(features_to_consider, axis=1), \n",
    "            annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Heatmap of Low-Correlation Features Removed')\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame with only highly correlated features and the target variable\n",
    "df_highly_correlated = df[features_to_consider + [target_column]]\n",
    "\n",
    "# Show the modified DataFrame with highly correlated features\n",
    "print(\"Modified DataFrame with Highly Correlated Features:\")\n",
    "print(df_highly_correlated.to_string())\n"
   ],
   "block_group": "c70117f1a990465ab9fa394421504bdf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "2e8817175f574137829392733792c5f9",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### Perform Feature Engineering"
   ],
   "block_group": "24e46b427870414c9eabe0236c5d2654"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "fa1ee544",
    "execution_start": 1699160272683,
    "execution_millis": 56,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "0570dbe567f041c699c7ec2e511d9b3d",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.241994600Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Assuming df_no_outliers is your DataFrame from which outliers have been removed\n",
    "X = df_highly_correlated[['bmi', 'bp', 's4', 's5']]  # Features\n",
    "y = df_highly_correlated['progression']  # Target\n",
    "\n",
    "# Initialize a PolynomialFeatures object\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Create polynomial features\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Convert the array back to a DataFrame (for better visualization and further processing)\n",
    "columns = poly.get_feature_names(['bmi', 'bp', 's4', 's5'])\n",
    "df_poly = pd.DataFrame(X_poly, columns=columns)\n",
    "\n",
    "# Check the head of the dataframe to see the engineered features\n",
    "print(df_poly.head())\n",
    "\n",
    "# Now df_poly contains the original features plus the polynomial features\n"
   ],
   "block_group": "8079976d5f5f45dc8720e21857f27661",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "90c100e7bdc44611963c6dabda1213a1",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### Perform Feature Scaling"
   ],
   "block_group": "7cd5fa9da01845a79ba7f71051cd6bf4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 0,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "859acf36d06849a986e7d6c4061974ae",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [],
   "block_group": "dcd5c4fbcdfa4aa8b1a6fa37e3d4ad3e"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 314,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "a3f3eb81e9d446fabc06be08bc0724ef",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "Scaling features to a similar range can make the training process more stable and often faster, with less risk of getting stuck in local optima. For gradient-based methods, it also ensures that the gradient descent moves smoothly towards the minima and that the steps taken in the parameter space are proportional."
   ],
   "block_group": "73b66312b6974db090bd95f8162678c5"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 0,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "ad7d0e0ef0ab48839a8b09347d12bf8c",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [],
   "block_group": "cd261475476845b59c3837028b24c5e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 696,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "5be7e88380cd490fa99bbd54350d2020",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "We use the `MinMaxScaler` is useful when you want to scale features to a specific range, typically [0, 1], which is particularly beneficial for algorithms that expect data to be within certain bounds, such as neural networks, or for visual representation purposes. It is well-suited for models that are sensitive to the scale of data and do not assume any specific distribution, including those based on gradient descent and distance calculations like k-NN. However, it's important to note that `MinMaxScaler` is sensitive to outliers, which can distort the actual data range and impact the scaling of the rest of the data. This could potentially affect model performance if outliers are present."
   ],
   "block_group": "daf3b431b18e411fa5f9b75ae921d9c9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "c4390b59",
    "execution_start": 1699160272759,
    "execution_millis": 41,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "980e85d70a5e42dca73d8032f1bb068c",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.241994600Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform it\n",
    "scaled_data = min_max_scaler.fit_transform(df)\n",
    "\n",
    "# Convert the scaled array back to a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "# Show the first few rows of the scaled data\n",
    "print(scaled_df.head())\n"
   ],
   "block_group": "562761b8b5944dd6a5c024b0b9cc95b8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "1c81f6dd6b4b40098d83e104930f5cf1",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### Now for training the model with pytorch we do the following:"
   ],
   "block_group": "ec7ddaf18913457fadbeafe905d2f374"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "6dd1557b4b734661a09ff0f529c8d2dd",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Convert dataframe to numpy for processing with PyTorch"
   ],
   "block_group": "89eb9642d59643669ae3c91b223c14cc"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "cf6b7f2bdbd64af98090b996b39afafc",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Since the dataset is time-sensitive, we use TimeSeriesSplit for creating our training/validation sets."
   ],
   "block_group": "7cc9db80244946b48f984742e946f80b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "598cb3603368412caa76b24d278714c0",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Converting to pytorch sensors"
   ],
   "block_group": "fc736546cbb54a90a090fc2be8e6ac18"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "841dacdf3f314e6bb27a27e341da3226",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Creating TensorDatasets for our DataLoader"
   ],
   "block_group": "24bb09301ae3405a8bcbeefa192adec0"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "52f8b22863ef431ca78e19ab75d17261",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- DataLoaders handle batching of data during training"
   ],
   "block_group": "9a702a19739c4b16accc9562b2316d38"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "8e9f336a",
    "execution_start": 1699160272794,
    "execution_millis": 30,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "4215f560e3ed4935aba3ff73a2f8143f",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.257002300Z"
    }
   },
   "source": [
    "\n",
    "# Convert dataframe to numpy for processing with PyTorch\n",
    "\n",
    "features = scaled_df.iloc[:, :-1].to_numpy()\n",
    "targets = scaled_df.iloc[:, -1].to_numpy()\n",
    "\n",
    "# Since the dataset is time-sensitive, we use TimeSeriesSplit for creating our training/validation sets.\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for train_index, val_index in tscv.split(features):\n",
    "    features_train, features_val = features[train_index], features[val_index]\n",
    "    targets_train, targets_val = targets[train_index], targets[val_index]\n",
    "\n",
    "# Converting numpy arrays to PyTorch tensors\n",
    "features_train_tensor = torch.tensor(features_train, dtype=torch.float32)\n",
    "targets_train_tensor = torch.tensor(targets_train, dtype=torch.float32).view(-1, 1)\n",
    "features_val_tensor = torch.tensor(features_val, dtype=torch.float32)\n",
    "targets_val_tensor = torch.tensor(targets_val, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Creating TensorDatasets for our DataLoader\n",
    "train_dataset = TensorDataset(features_train_tensor, targets_train_tensor)\n",
    "val_dataset = TensorDataset(features_val_tensor, targets_val_tensor)\n",
    "\n",
    "# DataLoaders handle batching of data during training\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)"
   ],
   "block_group": "cd652560a66e4c8abf0567fc26cab598",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9928\\2863986408.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Convert dataframe to numpy for processing with PyTorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mfeatures\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscaled_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mtargets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscaled_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'scaled_df' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "d709d6b3f9cc44fea2e815eb08678e7b",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### We use the following models:"
   ],
   "block_group": "a2089c13f818455ea1bb6b70daa7aa7d"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "481a813909634c6086a30ab1b7fa8e3a",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "-  MLP model with two hidden layers"
   ],
   "block_group": "d1c5d0c6df1447af8e96c776ad50592b"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "8fc6773796ab4f90b424d6e71e2d7521",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- A simple Linear Regression model which is equivalent to a single-layer perceptron without activation"
   ],
   "block_group": "da4ba2c5839545aaa0e375bfbb7d5efa"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "fcc5418fed5943a8bad9eb80ff42e8bc",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "-  DNN model with two hidden layers\n"
   ],
   "block_group": "60fe092401c342d08c41a9df435da833"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "37320766",
    "execution_start": 1699160272795,
    "execution_millis": 73,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "4b559462ab4d4308b651c068d71b080e",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.288257300Z"
    }
   },
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU(), # Activation function for first hidden layer\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(), # Activation function for second hidden layer\n",
    "            nn.Linear(hidden_size2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ],
   "block_group": "3a5fbeaf6ed14ebd9dc0cf52ca212123",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "90ef8b4d",
    "execution_start": 1699160272849,
    "execution_millis": 84,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "986c9136e1994a13bcc1e7a8dae0054d",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.288257300Z"
    }
   },
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ],
   "block_group": "51b513a750024c06965021af0e7a3e0e",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "8f01705b",
    "execution_start": 1699160272851,
    "execution_millis": 82,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "82b5620b7ea74637a9b02ec579d9b583",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.303877700Z"
    }
   },
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU(), # Activation function for first hidden layer\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(), # Activation function for second hidden layer\n",
    "            nn.Linear(hidden_size2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ],
   "block_group": "1483b825f3314b108f60165a48c04e5a",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "7b451485f39347f282d4d70f330c45b7",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### We instiantiate the models with the following parameters:"
   ],
   "block_group": "c9e87279d64546f1a461cb781a9eb69f"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 10,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "1ad509959dd64271819107d4e9ac24e5",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- input_size: The size of the input:"
   ],
   "block_group": "3f01c617e3cc418b92235a04c1822cf3"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 11,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "6333bd8b0e214b179aabf95beeefaff4",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- output_size: Regression has one output value"
   ],
   "block_group": "1fe98abecce040b08ca7b3f40d8291d5"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 12,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "de095b1a9fef48378ea74447192def7e",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- hidden_size1 = 64:  Size of first hidden layer"
   ],
   "block_group": "354761fc14b14fdd8d38b9aa614c855f"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 12,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "cde2b67c8beb4a7299a54d66cce5cbfa",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- hidden_size2 = 32:Size of second hidden layer"
   ],
   "block_group": "da456b921674453a8486a3ba9b10c30c"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "55deece7",
    "execution_start": 1699160272852,
    "execution_millis": 80,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "7e3b93d494084a65811896772076712d",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.303877700Z"
    }
   },
   "source": [
    "input_size = features_train_tensor.shape[1] \n",
    "output_size = 1 \n",
    "hidden_size1 = 64 \n",
    "hidden_size2 = 32 \n",
    "\n",
    "models = {\n",
    "    'MLP': MLP(input_size, hidden_size1, hidden_size2, output_size),\n",
    "    'LinearRegression': LinearRegression(input_size, output_size),\n",
    "    'DNN': DNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "}\n"
   ],
   "block_group": "5fe60170e95e41108e7779b08810980b",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_train_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9928\\1220414109.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0minput_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfeatures_train_tensor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0moutput_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mhidden_size1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m64\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mhidden_size2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m32\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'features_train_tensor' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "e050a91ba9ef437bb3769c30a0571db9",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### We Define the following loss functions:"
   ],
   "block_group": "fc6ced7c616e42c2a0b00079071d6d41"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 24,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "8507c058fcf44299be391ab7a5f9aaa2",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- MSE (Mean Squared Error): It is the average of the squared differences between the predicted and actual values, emphasizing larger errors."
   ],
   "block_group": "3b0eca52c6ce4596bc1fed9eccf06cad"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 25,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "7fdf0120b91e41c98e875c0c81a4fc9c",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- MAE (Mean Absolute Error): It is the average of the absolute differences between the predicted and actual values, giving equal weight to all errors."
   ],
   "block_group": "af326117771045d18000583bcd605367"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "0781b87e53314accaf781801c1c774d8",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### We define the following Optimizers:"
   ],
   "block_group": "69cd746f2a0041389fb755189b1cfe71"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 33,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "bf66f8d8f3234cbe8db5d6418034bd28",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- SGD (Stochastic Gradient Descent): It updates parameters using a fixed learning rate and based on the gradient of the loss with respect to a single batch; "
   ],
   "block_group": "a1b8f29cb9b04a7ba1a8593d892dba69"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 33,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "9023e59128dd4c23a683b2aab8c3669b",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- Adam (Adaptive Moment Estimation): It adapts the learning rate for each parameter by estimating first and second moments of the gradients."
   ],
   "block_group": "72a48bb8ecdf4f24ae75ed687a90adc1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 38,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "4c7eb87058304421a79602eea6825168",
    "deepnote_cell_type": "text-cell-bullet"
   },
   "source": [
    "- RMSProp (Root Mean Square Propagation): It adjusts the learning rate by dividing the gradient by a running average of its recent magnitude."
   ],
   "block_group": "80033efe99b0424e956e72a62cee2521"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 168,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "2d8d9609c7d3492bbbdde11d08eac139",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "The learning rate is a hyperparameter that controls the step size at each iteration while moving toward a minimum of a loss function in the training of neural networks."
   ],
   "block_group": "47a13668189d49c29e8a901678e32bf5"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "e553ef5d9cef49ecbc93a7660747fbba",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "We define the learning rate of 0.01"
   ],
   "block_group": "bb1e9fcb18c84c85bd8d5b3472d592fe"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 130,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "8b33a23354b14693b4b29b2e3c1b4484",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "An epoch in machine learning is one complete pass through the entire training dataset during the learning process of an algorithm."
   ],
   "block_group": "3e30e7f6d3e94492a825e19601308f29"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "fcac05629dd84ff9b4273322afe4e826",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "We define 100 epochs"
   ],
   "block_group": "78ed443435b04c388da708f9a0606f61"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 0,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "53c6437895c945db8c3adf8dc5caa4c2",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [],
   "block_group": "d76cff40bc3f47e1ab3432b50a4a50e2"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "4de79408",
    "execution_start": 1699160272865,
    "execution_millis": 75,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "7032bfd9e53f457a82674cba5da82b23",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.367384800Z"
    }
   },
   "source": [
    "# Define loss functions and optimizer choices\n",
    "loss_functions = {'MSE': nn.MSELoss(), 'MAE': nn.L1Loss()}\n",
    "optimizers = {'SGD': optim.SGD, 'Adam': optim.Adam, 'RMSProp': optim.RMSprop}\n",
    "\n",
    "# Set a learning rate for the optimizer\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100 # Number of epochs to train for\n",
    "loss_history = {name: {'train': [], 'val': []} for name in models} # Dictionary to store loss history\n"
   ],
   "block_group": "c41dc8b491ef4f9e966f935e2ff0365a",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9928\\2742311544.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Define loss functions and optimizer choices\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mloss_functions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'MSE'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMSELoss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'MAE'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mL1Loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0moptimizers\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'SGD'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSGD\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'Adam'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'RMSProp'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mRMSprop\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# Set a learning rate for the optimizer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "is_collapsed": false,
    "formattedRanges": [],
    "cell_id": "8f26d923a7334e0d9d197497d44969c3",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [],
   "block_group": "dcbb9c1398b7401880077041967fe3d6"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "091a322f1a834945b9f14e7a87e670dd",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### Train the models"
   ],
   "block_group": "fc312a01802c4869837112da3e886d3e"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "92ac5a27",
    "execution_start": 1699160272868,
    "execution_millis": 10098,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "1b11c5cb4f1c47ca9f25e8e0c9b31d6e",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.383449300Z"
    }
   },
   "source": [
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} model...\")\n",
    "    optimizer = optimizers['Adam'](model.parameters(), lr=learning_rate) # Choosing Adam optimizer\n",
    "    loss_fn = loss_functions['MSE'] # Choosing Mean Squared Error loss function for regression task\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set model to training mode\n",
    "        epoch_loss = 0.0\n",
    "        for batch_features, batch_targets in train_loader:\n",
    "            # Zero the gradients before running the backward pass.\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            predictions = model(batch_features)\n",
    "            # Compute loss\n",
    "            loss = loss_fn(predictions, batch_targets)\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # Perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # Accumulate loss\n",
    "            epoch_loss += loss.item() * batch_features.size(0) # Multiply by batch size to get absolute batch loss\n",
    "\n",
    "        # Compute average loss over the epoch\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval() # Set model to evaluation mode\n",
    "        with torch.no_grad(): # Turn off gradients for validation, saves memory and computations\n",
    "            val_loss = sum(loss_fn(model(batch_features), batch_targets).item() *\n",
    "                           batch_features.size(0) for batch_features, batch_targets in val_loader)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        # Store losses for plotting\n",
    "        loss_history[name]['train'].append(epoch_loss)\n",
    "        loss_history[name]['val'].append(val_loss)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]: Train Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')\n"
   ],
   "block_group": "5daa5ee78b69450d989327d6ca53aa74",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [
     {
      "type": "marks",
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 117,
      "fromCodePoint": 0
     }
    ],
    "cell_id": "f0c9226cdfd949a78a517471a0d67692",
    "deepnote_cell_type": "text-cell-p"
   },
   "source": [
    "Plot training and validation losses. This can be useful to see how the losses change over time and detect overfitting"
   ],
   "block_group": "d1cccdc315d54bc0a0ed5be7bf78d290"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "3d042c4d",
    "execution_start": 1699160283052,
    "execution_millis": 1112,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "07dbdb9ef0bf48f592a142276026acaa",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.383449300Z"
    }
   },
   "source": [
    "for name in models:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history[name]['train'], label='Train Loss')\n",
    "    plt.plot(loss_history[name]['val'], label='Validation Loss')\n",
    "    plt.title(f'Loss History for {name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "block_group": "4fd6339b7dd042e59971e579180befba",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "2e5c11983efa4df6804792a3c85730bd",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### Determine the best training model by comparing the loss"
   ],
   "block_group": "f80fc0f18e03413f90c1514009009f7b"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "ccf5accd",
    "execution_start": 1699160284177,
    "execution_millis": 10,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "1c03b7ff749a450b8e4a26348db3d781",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.383449300Z"
    }
   },
   "source": [
    "# Find the model with the lowest average validation loss\n",
    "avg_val_losses = {name: np.mean(history['val']) for name, history in loss_history.items()}\n",
    "best_model_name = min(avg_val_losses, key=avg_val_losses.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"The best model is {best_model_name} with an average validation loss of {avg_val_losses[best_model_name]:.4f}\")\n",
    "\n",
    "# Best model's parameters\n",
    "best_model_parameters = best_model.state_dict()\n"
   ],
   "block_group": "81ff72c5978b440da671c9d4dc481f00",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9928\\336748722.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Find the model with the lowest average validation loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mavg_val_losses\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'val'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhistory\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mloss_history\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mbest_model_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mavg_val_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mavg_val_losses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mbest_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mbest_model_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'loss_history' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "formattedRanges": [],
    "cell_id": "ee4a0deaa250459a98a160c572c22399",
    "deepnote_cell_type": "text-cell-h3"
   },
   "source": [
    "### Perform predictions and review model loss"
   ],
   "block_group": "7ee4f7e5401040bfae14fb3c84426a1e"
  },
  {
   "cell_type": "code",
   "metadata": {
    "source_hash": "f048bb17",
    "execution_start": 1699160284233,
    "execution_millis": 511,
    "deepnote_to_be_reexecuted": false,
    "cell_id": "85c557ede8c5455f831bb394e3577623",
    "deepnote_cell_type": "code",
    "ExecuteTime": {
     "start_time": "2023-11-05T05:17:51.415066400Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "best_model.eval()  # set the model to evaluation mode\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    for features, targets in val_loader:\n",
    "        preds = best_model(features)\n",
    "        loss = nn.MSELoss()(preds, targets)\n",
    "        val_loss += loss.item() * features.size(0)\n",
    "        predictions.extend(preds.view(-1).tolist())\n",
    "        actuals.extend(targets.view(-1).tolist())\n",
    "\n",
    "val_loss /= len(val_loader.dataset)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Convert predictions and actuals to numpy arrays for any further analysis\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "# Optionally, you might want to visualize the predictions vs actuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(actuals, label='Actual Values')\n",
    "plt.plot(predictions, label='Predictions')\n",
    "plt.title('Comparison of Actual and Predicted Values')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Target Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "block_group": "9b18e36ee3694c8ba2bcc9c3406eeccf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=32d4ae45-92b1-4635-a0c2-56c132478f05' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ],
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "deepnote": {},
  "orig_nbformat": 2,
  "deepnote_notebook_id": "71d482a598a143b58ce9745072e84cc1",
  "deepnote_execution_queue": [],
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 }
}
